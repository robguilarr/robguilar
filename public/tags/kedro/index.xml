<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Kedro - Tag - Roberto Aguilar</title>
        <link>https://robguilar.com/tags/kedro/</link>
        <description>Kedro - Tag - Roberto Aguilar</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is developed and posted only under Roberto&#39;s property</copyright><lastBuildDate>Sat, 20 May 2023 21:57:40 &#43;0800</lastBuildDate><atom:link href="https://robguilar.com/tags/kedro/" rel="self" type="application/rss+xml" /><item>
    <title>Player Retention and Cohorts Creation Pipeline in Brawl Stars with Non-Supervised Models</title>
    <link>https://robguilar.com/posts/brawlstars_retention_pipeline/</link>
    <pubDate>Sat, 20 May 2023 21:57:40 &#43;0800</pubDate><guid>https://robguilar.com/posts/brawlstars_retention_pipeline/</guid>
    <description><![CDATA[<p>Brawl Stars is one of the action-packed multiplayer gaming experiences offered by Supercell, the Finnish mobile game development company known for hits like Clash of Clans and Clash Royale. This company has consistently churned out hit after hit, racking up billions of downloads and earning a reputation as one of the most innovative and successful mobile game studios in the world. Part of their success is due to their solid data practices.</p>
<p>Retention metrics tracking is crucial for the long-term sustainability of mobile games like Brawl Stars, particularly during soft launches. These metrics are used to measure how many players continue to play the game after initial installation and engagement.</p>
<p>By analyzing these metrics, game developers can identify areas where players may be dropping off and make changes to improve the user experience and keep players engaged over time. This is essential for the success of a mobile game, as high retention rates lead to more in-app purchases and longer overall player lifetimes. Given the competitive landscape of mobile gaming, tracking retention metrics is a key component in keeping a game relevant and profitable over the long term.</p>
<hr>
<p align='center'> <i class="fas fa-exclamation-circle fa-fw"></i>&nbsp;<b>Important: Any views, material or statements expressed are mines and not those of my employer</b> </p>
<hr>
<div class="details admonition info open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-info-circle fa-fw"></i>Looking for an interactive experience?<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">üöÄ Access the Kedro Pipeline Visualization, available <a href="https://brawlstars-retention-pipeline-6u27jcczha-uw.a.run.app/">here</a>; or you can download the <a href="https://github.com/robguilarr/Brawlstars-retention-pipeline">source code</a> from GitHub</div>
        </div>
    </div>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/CaryjOdYFa0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<hr>
<h2 id="-introduction-to-the-problem">‚ö†Ô∏è Introduction to the problem</h2>
<h3 id="hypothesis">Hypothesis</h3>
<p>The analytics team of a mobile gaming developer is facing a problem while producing bounded retention metrics for player cohorts based on the game modes offered. They need a fully parameterized way to produce these metrics, instead of hardcoded methods per iteration.</p>
<p>Currently, the analytics team mines data batches of over 20,000 players in a single run to create unbounded retention metrics, and the job is processed every 56 days. However, the team need to track user retention within a given time frame and qualify player preferences based on the game modes offered and their game-experience.</p>
<p>Also, they require a model that can define cohorts based on the installation date or any other classification parameter and includes a feature store to keep track of the features used. Additionally, they would like to store the hyperparameters, evaluation scores, and estimators used for each experiment on a Cloud Service to reuse specific models later.</p>
<ul>
<li>$H_0:$ The pipeline is sufficient to produce retention metrics for player cohorts based on the game modes offered, and there is no need for a fully parameterized tool to create these metrics with bounded approaches.</li>
<li>$H_1:$ The current pipeline is not sufficient, and a fully parameterized tool is required to track user retention within a given time frame and qualify player preferences based on the game modes offered. Additionally, a Cloud Service-based feature store and model registry are needed to keep track of experiment versions.</li>
</ul>
<p align="middle"></p>
<h3 id="potential-stakeholders">Potential Stakeholders</h3>
<ul>
<li>Designers: Game Designers are interested in user retention metrics to understand how users are interacting with the game and to identify any areas that need to be improved to keep users engaged and coming back to the game.</li>
<li>Product / Project Managers: Responsible for defining the goals and objectives for the game and ensuring that those goals are met, they need to follow user retention metrics to understand how well the game is performing in terms of retaining users and whether any changes need to be made to the game to improve retention.</li>
<li>Marketer: Understand how effective their marketing campaigns are in ‚Äúkeeping users engaged‚Äù with the game, and whether any changes need to be made to the campaigns to improve retention.</li>
<li>Programmers: Interested in identifying any technical issues that may be causing users to leave the game and make improvements to the game to improve retention.</li>
<li>Publisher: Need to understand the financial performance of the game and whether it is generating sufficient revenue to justify the investment. They are also interested in understanding the potential for future growth and the impact of retention on the game&rsquo;s long-term sustainability.</li>
</ul>
<p><strong>Note:</strong>¬†To facilitate the understanding of the roles of the development team, I invite you to take a look at¬†<strong><a href="https://www.robguilar.com/posts/gamedev_structure/" target="_blank" rel="noopener noreffer">this</a></strong>¬†diagram that I designed.</p>
<hr>
<h2 id="-about-the-data">üì• About the data</h2>
<h3 id="source-data">Source data</h3>
<p>The <a href="https://developer.brawlstars.com/#/" target="_blank" rel="noopener noreffer">Brawl Stars Public API</a> is the source of the data, which is accessible to anyone and completely free to use. By entering an identifier in the request function, the API gathers data on the player associated with that identifier, also known as the &ldquo;Player Tag&rdquo;.</p>
<p>Each user account has a unique player tag, which I collected from a sample shared by <a href="https://www.kaggle.com/datasets/sirwerto/brawlstars-players-tags" target="_blank" rel="noopener noreffer">@SirWerto</a> on Kaggle. To supplement our tag list, also utilized the <code>.ranking()</code> function of <a href="https://brawlstats.readthedocs.io/en/latest/api.html" target="_blank" rel="noopener noreffer">Brawlstats</a>, an open-source Python library. The dataset contains a total of 23841 Player Tags, which are saved in a <code>.txt</code> file and stored in a Google Cloud Bucket folder labeled as <code>/01_player_tags</code>.</p>
<h3 id="data-catalog-structure">Data Catalog structure</h3>
<p>Versioning plays a vital role in maintaining organized and traceable files. To accomplish this, we utilize a hierarchical storage approach, incorporating a timestamp in EPOCH format as a reference point. In order to leverage this functionality, we will employ the Kedro <a href="https://docs.kedro.org/en/stable/data/data_catalog.html#version-datasets-and-ml-models" target="_blank" rel="noopener noreffer">versioning</a> feature.</p>
<p>To ensure a comprehensive record of models, estimators, and features used in each run, the catalog offers eight distinct storage endpoints, including <code>/06_viz_data</code>, <code>/07_feature_store</code>, and <code>/08_model_registry</code>, all of which are versioned. By using versioning to manage and maintain these files, teams can easily track data and model changes, to ensure that each iteration is saved for future reference.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">gcp</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># ----- Bucket Parent Locations -----</span><span class="w">
</span><span class="w">    </span><span class="nt">player_tags</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/01_player_tags</span><span class="w">
</span><span class="w">    </span><span class="nt">raw_battlelogs</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/02_raw_battlelogs</span><span class="w">
</span><span class="w">    </span><span class="nt">raw_metadata</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/03_raw_metadata</span><span class="w">
</span><span class="w">    </span><span class="nt">enriched_data</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/04_enriched_data</span><span class="w">
</span><span class="w">    </span><span class="nt">curated_data</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/05_curated_data</span><span class="w">
</span><span class="w">    </span><span class="nt">viz_data</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/06_viz_data</span><span class="w">
</span><span class="w">    </span><span class="nt">feature_store</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/07_feature_store</span><span class="w">
</span><span class="w">    </span><span class="nt">model_registry</span><span class="p">:</span><span class="w"> </span><span class="l">gs://animus-memory-bucket/brawlstars/08_model_registry</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c"># ----- Main GCP Project ID -----</span><span class="w">
</span><span class="w">    </span><span class="nt">project_id</span><span class="p">:</span><span class="w"> </span><span class="l">abstergo-corp-id</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>To easily locate the endpoint of each GCP Bucket output, simply refer to the <a href="https://github.com/robguilarr/Brawlstars-retention-pipeline/blob/main/conf/gcp/catalog.yml" target="_blank" rel="noopener noreffer">conf/gcp/catalog.yml</a> file. This file defines each destination using Dataset Groups, as shown in the following example:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">_pyspark</span><span class="p">:</span><span class="w"> </span><span class="cp">&amp;pyspark</span><span class="w">
</span><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">spark.SparkDataSet</span><span class="w">
</span><span class="w">  </span><span class="nt">file_format</span><span class="p">:</span><span class="w"> </span><span class="l">parquet</span><span class="w">
</span><span class="w">  </span><span class="nt">load_args</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">header</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">save_args</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l">overwrite</span><span class="w">
</span><span class="w">    </span><span class="nt">sep</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;,&#39;</span><span class="w">
</span><span class="w">    </span><span class="nt">header</span><span class="p">:</span><span class="w"> </span><span class="kc">True</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">_pandas</span><span class="p">:</span><span class="w"> </span><span class="cp">&amp;pandas</span><span class="w">
</span><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">pandas.CSVDataSet</span><span class="w">
</span><span class="w">  </span><span class="nt">load_args</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">sep</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;,&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">save_args</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">index</span><span class="p">:</span><span class="w"> </span><span class="kc">False</span><span class="w">
</span><span class="w">  </span><span class="nt">fs_args</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">project</span><span class="p">:</span><span class="w"> </span><span class="l">${gcp.project_id}</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">cohort_activity_data@pyspark</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">&lt;&lt;</span><span class="p">:</span><span class="w"> </span><span class="cp">*pyspark</span><span class="w">
</span><span class="w">  </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="l">${gcp.curated_data}/cohort_activity_data.parquet</span><span class="w">
</span><span class="w">  </span><span class="nt">layer</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;primary&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">player_metadata@pandas</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">&lt;&lt;</span><span class="p">:</span><span class="w"> </span><span class="cp">*pandas</span><span class="w">
</span><span class="w">  </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="l">${gcp.raw_metadata}/player_metadata.csv</span><span class="w">
</span><span class="w">  </span><span class="nt">layer</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;raw&#34;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>The outputs <code>cohort_activity_data@pyspark</code> and <code>player_metadata@pandas</code> are specifically mapped to the <code>_pyspark</code> and <code>_pandas</code> dataset groups, respectively. Moreover, we can assign Layers to these outputs, providing users with a clear understanding of their utility as intermediate data sources, for analysis, or as input for machine learning models.</p>
<p>Seven layers were defined in the catalog: raw, primary, model input, feature, models, model output, and reporting. To go deeper into the Layer definitions and best practices, I suggest reading the following <a href="https://towardsdatascience.com/the-importance-of-layered-thinking-in-data-engineering-a09f685edc71" target="_blank" rel="noopener noreffer">article</a> by Joel Schwarzmann (2021).</p>
<hr>
<h2 id="pipelines-workflow">‚ö°Pipelines workflow</h2>
<p>The pipeline architecture consists of five modular pipelines, with a total of 14 nodes. These pipelines will be constructed utilizing the open-source framework, <a href="https://kedro.org/" target="_blank" rel="noopener noreffer">Kedro</a>.</p>
<ul>
<li>Two of these pipelines, <code>battlelogs_request_preprocess</code> and <code>metadata_request_preprocess</code>, will use asynchronous coroutines to request data from the API and Spark for preprocessing. The requested data will be processed in batches of over 400 MB using only Spark to avoid communication overhead while minimizing the number of actions taken to take advantage of the worker&rsquo;s process fluency.</li>
<li>The <code>events_activity_segmentation</code> pipeline will use Spark SQL API to produce retention metrics. This pipeline will use the data gathered from the requesting nodes. It is important to consider the data dependency between functions, which is why multithreading won&rsquo;t be used.</li>
<li>Another pipeline, the <code>player_cohorts_classifier</code>, will perform a multiprocessing step over a Grid Search and cross-validation across multiple cores to evaluate the best quantity of clusters in which we can classify the players based on the game modes‚Äô behaviors. This depends on the distortion rate and the hyperparameters defined by the user.</li>
<li>The last modular pipeline, <code>player_activity_clustering_merge</code>, will use the curated data to produce retention plots. It will use a single Python processing since it uses filtered data, which is a smaller subset.</li>
</ul>
<p>This pipeline was designed to speed up processing by parallelizing. We can calculate the theoretical speedup by applying <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law" target="_blank" rel="noopener noreffer">Amdahl&rsquo;s Law</a>.</p>
<p>$$
S = \frac{1}{1-P+\frac{P}{N}} = \frac{1}{1-0.64286+\frac{0.64286}{10}} = 2.52
$$</p>
<p>The theoretical speedup will be approximately 2.52 for a single-machine cluster. Here, <em>S</em> represents theoretical speedup, <em>P</em> represents the fraction of the workload that can be parallelized, and <em>N</em> represents the number of processors.</p>
<p>If you want to learn more about the appropriate use cases for multithreading and multiprocessing, I highly recommend watching <a href="https://www.youtube.com/watch?v=w2eUdxPQQ78" target="_blank" rel="noopener noreffer">this conference video</a> by Chin Hwee Ong (Pycon Taiwan 2020). It&rsquo;s one of the best resources to get started.</p>
<hr>
<h3 id="-battlelogs-and-metadata-request-pipelines">‚öîÔ∏è Battlelogs and Metadata Request Pipelines</h3>
<p><strong>Pipeline <code>battlelogs_request_preprocess</code> and <code>metadata_request_preprocess</code></strong></p>
<p>Both pipelines follow the same structure, the only difference is the request function used to gather the data from the API, one uses <code>.get_battle_logs()</code>, and the other uses the <code>.get_player()</code> function. And from these functions come two different data models <a href="https://brawlstats.readthedocs.io/en/latest/api.html#battle-logs" target="_blank" rel="noopener noreffer">battle logs</a> and <a href="https://brawlstats.readthedocs.io/en/latest/api.html#player" target="_blank" rel="noopener noreffer">players</a>.</p>
<p align="middle"></p>
<p><strong>Node: <code>battlelogs_request_node</code> and <code>player_metadata_request_node</code></strong></p>
<p>The inconsistent batch sizes of our data make it unsuitable to rely on an <code>O(n)</code> frequency expectation, due factors such as:</p>
<ul>
<li>Product cycle (e.g., new feature or season launch).</li>
<li>Player longevity can affect the data (e.g., newer players with less than 25 sessions).</li>
</ul>
<p>To extract the logs, I opted to use low-level APIs, specifically Python&rsquo;s asynchronous coroutines. This approach allows executing one batch while waiting for a response from another, which is particularly helpful when dealing with variable batch sizes or waiting for processing, such as querying from a SQL database. However, the <a href="https://brawlstats.readthedocs.io/en/latest/_modules/brawlstats/core.html#Client.get_battle_logs" target="_blank" rel="noopener noreffer">API wrapper</a> used limits the multithreading pool size to 10, which means we had to separate the tags into batches of that size.</p>
<p>The main advantage of this approach is that it makes the code independent of the processor&rsquo;s clock speed, avoiding waiting times between requests. Although Python&rsquo;s <a href="https://realpython.com/python-gil/" target="_blank" rel="noopener noreffer">Global Interpreter Lock (GIL)</a> restricts running multiple threads simultaneously, we overcame this limitation by using coroutines to process future objects. If the pool size weren&rsquo;t limited, we could have used multithreading instead. Overall, this strategy allowed us to process our data more efficiently and achieve better results.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">battlelogs_request</span><span class="p">(</span>
    <span class="n">player_tags_txt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">parameters</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    Extracts battlelogs from Brawlstars API by asynchronously executing a list of
</span><span class="s2">    futures objects, each of which is made up of an Async thread task due to blocking
</span><span class="s2">    call limitations of the api_request submodule.
</span><span class="s2">    Args:
</span><span class="s2">        player_tags_txt: A list of player tags.
</span><span class="s2">        parameters: Additional parameters to be included in the API request.
</span><span class="s2">    Returns:
</span><span class="s2">         A structured DataFrame that concatenates all the battlelogs of the players.
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="c1"># Get key and validate it exists</span>
    <span class="n">API_KEY</span> <span class="o">=</span> <span class="n">conf_credentials</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;brawlstars_api&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;API_KEY&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">API_KEY</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="ne">AssertionError</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&#34;No API key has been defined. Request one at https://developer.brawlstars.com/&#34;</span>
        <span class="p">)</span>

    <span class="c1"># Create a BrawlStats client object to interact with the API. Note: the</span>
    <span class="c1"># &#34;prevent_ratelimit&#34; function in the source code can be used this behavior</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">brawlstats</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">API_KEY</span><span class="p">)</span>

    <span class="c1"># Split the player tags text by commas to create a list of player tags.</span>
    <span class="n">player_tags_txt</span> <span class="o">=</span> <span class="n">player_tags_txt</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">api_request</span><span class="p">(</span><span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="s2">&#34;&#34;&#34;Requests and structures the 25 most recent battle logs from the Brawl
</span><span class="s2">        Stars API for a given player.&#34;&#34;&#34;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Retrieve raw battle logs data from API</span>
            <span class="n">player_battle_logs</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_battle_logs</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span><span class="o">.</span><span class="n">raw_data</span>
            <span class="c1"># Normalize data into structured format</span>
            <span class="n">player_battle_logs_structured</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">json_normalize</span><span class="p">(</span><span class="n">player_battle_logs</span><span class="p">)</span>
            <span class="c1"># Add player ID to DataFrame</span>
            <span class="n">player_battle_logs_structured</span><span class="p">[</span><span class="s2">&#34;player_id&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tag</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;No battle logs extracted for player </span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
            <span class="n">player_battle_logs_structured</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
            <span class="k">pass</span>
        <span class="k">return</span> <span class="n">player_battle_logs_structured</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">api_request_async</span><span class="p">(</span><span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="s2">&#34;&#34;&#34;
</span><span class="s2">        Transform non-sync request function to async coroutine, which creates
</span><span class="s2">        a future object by API request.
</span><span class="s2">        The Coroutine contains a blocking call that won&#39;t return a log until it&#39;s
</span><span class="s2">        complete. So, to run concurrently, await the thread and not the coroutine by
</span><span class="s2">        using this method.
</span><span class="s2">        &#34;&#34;&#34;</span>
        <span class="k">return</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">to_thread</span><span class="p">(</span><span class="n">api_request</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">spawn_request</span><span class="p">(</span><span class="n">player_tags_txt</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="s2">&#34;&#34;&#34;
</span><span class="s2">        This asynchronous function takes a list of player tags as input and creates a
</span><span class="s2">        list of coroutines that request the player&#39;s battlelogs data. It then
</span><span class="s2">        schedules their execution and waits for them to complete by using the
</span><span class="s2">        asyncio.gather() method. Finally, it concatenates all the dataframes returned by
</span><span class="s2">        the coroutines into one dataframe.
</span><span class="s2">        &#34;&#34;&#34;</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Battlelogs request process started&#34;</span><span class="p">)</span>
        <span class="c1"># Create a list of coroutines and schedule their execution</span>
        <span class="n">requests_tasks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">asyncio</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">api_request_async</span><span class="p">(</span><span class="n">tag</span><span class="p">))</span> <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">player_tags_txt</span>
        <span class="p">]</span>
        <span class="c1"># Wait for all tasks to complete and gather their results</span>
        <span class="n">battlelogs_data_list</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">requests_tasks</span><span class="p">)</span>
        <span class="c1"># Concatenate all the dataframes returned by the coroutines into one</span>
        <span class="n">raw_battlelogs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">battlelogs_data_list</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&#34;Battlelogs request process finished in </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="si">}</span><span class="s2"> seconds&#34;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">raw_battlelogs</span>

    <span class="k">def</span> <span class="nf">activate_request</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="s2">&#34;&#34;&#34;
</span><span class="s2">        This function checks if a sampling limit is provided, and if so, it calls the
</span><span class="s2">        spawn_request() function to request the battlelogs data of the first n
</span><span class="s2">        players. If n is not provided, it splits the player tags list into batches of 10
</span><span class="s2">        and calls the spawn_request() function for each batch. It then concatenates
</span><span class="s2">        the dataframes returned by each call into one.
</span><span class="s2">        &#34;&#34;&#34;</span>
        <span class="n">raw_battlelogs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">n</span><span class="p">:</span>
            <span class="c1"># Call spawn_request() for the first n players</span>
            <span class="n">raw_battlelogs</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">spawn_request</span><span class="p">(</span><span class="n">player_tags_txt</span><span class="p">[:</span><span class="n">n</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Split the tags list into batches of 10 and call spawn_request() for each</span>
            <span class="n">split_tags</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">player_tags_txt</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">player_tags_txt</span><span class="p">)</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">split_tags</span><span class="p">:</span>
                <span class="n">raw_battlelogs_tmp</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">spawn_request</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
                <span class="c1"># Concatenate the dataframes returned by each call into one</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">raw_battlelogs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">raw_battlelogs</span><span class="p">,</span> <span class="n">raw_battlelogs_tmp</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>

        <span class="k">return</span> <span class="n">raw_battlelogs</span>

    <span class="c1"># Call activate_request() with the specified battlelogs_limit parameter</span>
    <span class="n">raw_battlelogs</span> <span class="o">=</span> <span class="n">activate_request</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&#34;battlelogs_limit&#34;</span><span class="p">])</span>

    <span class="c1"># Replace dots in column names with underscores</span>
    <span class="n">raw_battlelogs</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">col_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;.&#34;</span><span class="p">,</span> <span class="s2">&#34;_&#34;</span><span class="p">)</span> <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">raw_battlelogs</span><span class="o">.</span><span class="n">columns</span>
    <span class="p">]</span>

    <span class="c1"># Check if the data request was successful</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">raw_battlelogs</span><span class="o">.</span><span class="n">empty</span>
    <span class="k">except</span> <span class="ne">AssertionError</span><span class="p">:</span>
        <span class="c1"># Log an error message if no Battlelogs were extracted</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;No Battlelogs were extracted. Please check your Client Connection&#34;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">raw_battlelogs</span>
</code></pre></td></tr></table>
</div>
</div><p>Here was collected a substantial amount of battle logs and player metadata, amounting to 476 MB and 453 MB, respectively. To analyze the process efficiency, was compared a synchronous process using a loop with an asynchronous process. The results were benchmarked:</p>
<ul>
<li>The asynchronous process completed the task in just 287.93 seconds.</li>
<li>The synchronous process took 1004.54 seconds.</li>
</ul>
<p>This translates to a 71% improvement in speed for the logs request, demonstrating the effectiveness of the new approach. Upon further analysis, out of the 23841 Player Tags, only 9104 had a battle log registry. Nevertheless, we managed to retrieve player metadata for 22738 of them, which is a good number considering we were using a public non-official API.</p>
<p><strong>Node: <code>battlelogs_filtering_node</code> and <code>metadata_preparation_node</code></strong></p>
<p>The node serves two main purposes:</p>
<ul>
<li>Transform retrieved data into a Spark data frame, ensuring accurate and consistent data with the expected data types.</li>
<li>Enable users to specify time ranges for player cohorts. This feature empowers users to customize the quantity and number of cohorts needed for their specific study.</li>
</ul>
<p>For instance, in the following example, the cohorts are divided into 8 time-ranges. Events with missing identifiers are automatically excluded. This function assumes that the user requires a model capable of defining cohorts based on factors such as installation date or any other classification parameter.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># ----- Parameters for preprocessing and filtering ----</span><span class="w">
</span><span class="w"></span><span class="nt">battlelogs_filter</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">exclude_missing_events</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">cohort_time_range</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2019-10-11&#34;,&#34;2020-04-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2020-04-11&#34;,&#34;2020-10-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2020-10-11&#34;,&#34;2021-04-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2021-04-11&#34;,&#34;2021-10-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2021-10-11&#34;,&#34;2022-04-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2022-04-11&#34;,&#34;2022-10-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2022-10-11&#34;,&#34;2023-04-10&#34;)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(&#34;2023-04-11&#34;,&#34;2023-10-10&#34;)</span><span class="w">
</span><span class="w">  </span><span class="nt">raw_battlelogs_schema</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="s2">&#34;battleTime STRING, 
</span><span class="s2">       event_id BIGINT, 
</span><span class="s2">       event_mode STRING,
</span><span class="s2">       event_map STRING,
</span><span class="s2">       battle_mode STRING,
</span><span class="s2">       battle_type STRING,
</span><span class="s2">       battle_result STRING,
</span><span class="s2">       battle_duration BIGINT,
</span><span class="s2">       battle_trophyChange BIGINT,
</span><span class="s2">       battle_starPlayer_tag STRING,
</span><span class="s2">       battle_starPlayer_name STRING,
</span><span class="s2">       battle_starPlayer_brawler_id BIGINT,
</span><span class="s2">       battle_starPlayer_brawler_name STRING,
</span><span class="s2">       battle_starPlayer_brawler_power BIGINT,
</span><span class="s2">       battle_starPlayer_brawler_trophies BIGINT,
</span><span class="s2">       battle_teams STRING,
</span><span class="s2">       battle_rank BIGINT,
</span><span class="s2">       battle_players STRING,
</span><span class="s2">       player_id STRING,
</span><span class="s2">       battle_starPlayer STRING,
</span><span class="s2">       battle_bigBrawler_tag STRING,
</span><span class="s2">       battle_bigBrawler_name STRING,
</span><span class="s2">       battle_bigBrawler_brawler_id BIGINT,
</span><span class="s2">       battle_bigBrawler_brawler_name STRING,
</span><span class="s2">       battle_bigBrawler_brawler_power BIGINT,
</span><span class="s2">       battle_bigBrawler_brawler_trophies BIGINT,
</span><span class="s2">       battle_level_name STRING,
</span><span class="s2">       battle_level_id BIGINT&#34;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><hr>
<h3 id="-events-and-activity-segmentation-pipeline">üï∞Ô∏è Events and Activity Segmentation Pipeline</h3>
<p><strong>Pipeline <code>events_activity_segmentation</code></strong></p>
<p>Our goal is to transform raw data into valuable insights. To achieve this, we will focus on processing and filtering battle logs to produce ‚Äúactivity‚Äù data. This includes segmentations per event type, retention metrics, and ratios based on retention. With these metrics, we can gain a deeper understanding of user behavior and make informed decisions that drive growth.</p>
<p align="middle"></p>
<p><strong>Node: <code>battlelogs_deconstructor_node</code></strong></p>
<p>To understand the basic game modes of this mobile game, an extensive research was required. All assumptions made in the event deconstruction process are based on the information provided by the <a href="https://brawlstars.fandom.com/wiki/Category:Events" target="_blank" rel="noopener noreffer">Brawl Stars Fandom Wiki</a>.</p>
<p>The deconstruction process will classify the <code>battle_teams</code> column and divide all players in each session into groups based on the number of team members defined by the event type. These event types are categorized according to specific parameters, enabling users to easily classify events based on the distribution of players' teams per session.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># ----- Parameters to deconstruct the data by event ----</span><span class="w">
</span><span class="w"></span><span class="nt">battlelogs_deconstructor</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">event_solo</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s1">&#39;soloShowdown&#39;</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">event_duo</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s1">&#39;duoShowdown&#39;</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">event_3v3</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s1">&#39;gemGrab&#39;</span><span class="p">,</span><span class="s1">&#39;brawlBall&#39;</span><span class="p">,</span><span class="s1">&#39;bounty&#39;</span><span class="p">,</span><span class="s1">&#39;heist&#39;</span><span class="p">,</span><span class="s1">&#39;hotZone&#39;</span><span class="p">,</span><span class="s1">&#39;knockout&#39;</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">event_special</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s1">&#39;roboRumble&#39;</span><span class="p">,</span><span class="s1">&#39;bossFight&#39;</span><span class="p">,</span><span class="s1">&#39;lastStand&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;bigGame&#39;</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">standard_columns</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battlelog_id&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;cohort&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battleTime&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;player_id&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;event_id&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;event_mode&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;event_map&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;is_starPlayer&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battle_type&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battle_result&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battle_rank&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battle_duration&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battle_trophyChange&#39;</span><span class="w">
</span><span class="w">    </span>- <span class="s1">&#39;battle_level_name&#39;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>The use of parameters to segment the raw battle logs data is interpreted as follows:</p>
<ul>
<li>The <code>battle_teams</code> column in the JSON files contains a massive collection of data. When the battle type is in the list <code>['gemGrab','brawlBall','bounty','heist','hotZone','knockout']</code>, the code recognizes this as 3 vs 3 events, meaning that the battle teams column contains information on all six players.</li>
</ul>
<p>To create the <code>players_collection</code> and <code>brawlers_collection</code> data, the six players are divided into two groups. This division results in two collections that provide valuable insights into player behavior and <a href="https://brawlstars.fandom.com/wiki/Category:Brawlers" target="_blank" rel="noopener noreffer">brawler</a> selection.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">players_collection &gt;&gt; [[#2882QV9J0, #28Y9GJC0L, #2UPL0QCYG], [#U08LRGYJ, #2QQ9GY2YL, #22UJ88YQ9]]

brawlers_collection &gt;&gt; [[CROW, MORTIS, BUZZ], [MORTIS, SURGE, DYNAMIKE]]
</code></pre></td></tr></table>
</div>
</div><p>By conducting an interaction study between players and the brawlers or characters they use, a data scientist can extract valuable insights into gameplay. For instance, if you&rsquo;re curious about how the exploder function works, you&rsquo;ll find this code particularly useful. Its high density is evidence of Spark high performance, which has enabled the minimization of Spark actions performed. However, you can satisfy your curiosity <a href="https://github.com/robguilarr/Brawlstars-retention-pipeline/blob/main/src/brawlstars_etl/pipelines/events_activity_segmentation/nodes.py" target="_blank" rel="noopener noreffer">here</a>.</p>
<p><strong>Node: <code>activity_transformer_node</code></strong></p>
<p>Imagine having the capacity to transform filtered battle logs activity into a wrapped format data frame that delivers retention metrics and n-sessions at the player level of granularity. That&rsquo;s exactly what this node does. Using a set of customizable parameters, it extracts the retention and number of sessions based on a <code>cohort frequency</code> parameter:</p>
<ul>
<li>When you select <code>daily</code> granularity, the cohort period is based on the day of the user&rsquo;s first event, showing you the number of sessions logged per user on the day they installed the game, on the day they returned, and so on.</li>
<li>If you choose <code>weekly</code> granularity, the cohort period is based on the first consecutive Monday on or after the day of the user&rsquo;s first event. This allows you to track user behavior on a weekly basis, providing valuable insights into how engagement fluctuates throughout the week.</li>
<li>And if you opt for <code>monthly</code> granularity, the cohort period is based on the first day of the month in which the user&rsquo;s first event occurred. This gives you an overview of user behavior on a monthly basis, perfect for understanding trends over time.</li>
</ul>
<p>By default, this node is set to <code>daily</code>, making it easy to get started and quickly visualize your data. With its intuitive and powerful features, you&rsquo;ll gain deeper insights into your users' behavior, and be able to optimize your game for even greater success.</p>
<p align="middle"></p>
<p>Each one of the days to measure can be defined as parameters as well, to let the user define the criteria of the retention study:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># ----- Parameters to extract activity day per user ----</span><span class="w">
</span><span class="w"></span><span class="nt">activity_transformer</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">cohort_frequency</span><span class="p">:</span><span class="w"> </span><span class="l">daily</span><span class="w">
</span><span class="w">  </span><span class="nt">retention_days</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="m">0</span><span class="w">
</span><span class="w">    </span>- <span class="m">1</span><span class="w">
</span><span class="w">    </span>- <span class="m">3</span><span class="w">
</span><span class="w">    </span>- <span class="m">7</span><span class="w">
</span><span class="w">    </span>- <span class="m">14</span><span class="w">
</span><span class="w">    </span>- <span class="m">28</span><span class="w">
</span><span class="w">    </span>- <span class="m">56</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p><strong>Node: <code>ratio_register_node</code></strong></p>
<p>In the final stage of this pipeline, we&rsquo;ll generate bounded retention metrics as ratios. These metrics will be used to demonstrate the effectiveness of our approach. While I may not have experience in gaming, I understand the importance of accurately measuring retention ratios. To ensure our metrics are properly measured, we&rsquo;ll ask the <a href="https://a16z.com/about/" target="_blank" rel="noopener noreffer">Andreessen Horowitz</a> Partner, <a href="https://andrewchen.com/" target="_blank" rel="noopener noreffer">Andrew Chen</a>, a leading expert in the field.</p>
<div style="display: flex; justify-content: center;">
  <blockquote class="twitter-tweet"><p lang="en" dir="ltr">6) D1/D7/D30 that exceeds 60/30/15 (daily frequency)<br>7) revenue or activity expansion on a *per user* basis over time -- indicates deeper engagement / habit formation<br>8) &gt;60% organic acquisition -- CAC doesn&#39;t even matter!<br><br>Having even one is impressive -- it&#39;d make me sit up!</p>&mdash; andrew chen (@andrewchen) <a href="https://twitter.com/andrewchen/status/1184170127345893376?ref_src=twsrc%5Etfw">October 15, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
<p>Well, the consultation went smoothly. So, we&rsquo;re ready to define our parameters. Specifically, we&rsquo;ll be establishing ratios for individual retention metrics, as well as ratios for combined retention metrics (analytical ratios):</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># ----- Parameters to aggregate retention metrics ----</span><span class="w">
</span><span class="w"></span><span class="nt">ratio_register</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">ratios</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">(1,0)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(3,0)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(7,0)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(14,0)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(28,0)</span><span class="w">
</span><span class="w">    </span>- <span class="l">(56,0)</span><span class="w">
</span><span class="w">  </span><span class="nt">analytical_ratios</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">(3,1)</span><span class="w"> </span><span class="c"># D3/D1</span><span class="w">
</span><span class="w">    </span>- <span class="l">(7,3)</span><span class="w"> </span><span class="c"># D7/D3</span><span class="w">
</span><span class="w">    </span>- <span class="l">(28,7)</span><span class="w"> </span><span class="c"># D28/D7</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>To gain a deeper understanding of retention metrics, I highly recommend delving into Timothy Daniel&rsquo;s (2022) <a href="https://medium.com/permutable-analytics/how-to-calculate-benchmark-day-1-day-7-and-day-30-retention-in-amplitude-analytics-d500a77eae04" target="_blank" rel="noopener noreffer">insightful article</a>.</p>
<p>In essence, there are two types of retention metrics: bounded and unbounded. While the latter includes unique users returning on the same day or later, the first one is considered more reliable because it&rsquo;s not influenced by new data coming in. So if we&rsquo;re aiming for accuracy and consistency in the retention measurements, bounded retention should be the go-to.</p>
<p>This is how the output should look like:</p>
<p align="middle"></p>
<hr>
<h3 id="-player-classification-and-cohorts-creation-pipeline">üíÄ Player Classification and Cohorts Creation Pipeline</h3>
<p><strong>Pipeline <code>player_cohorts_classifier</code></strong></p>
<p>This pipeline is a parametrized method for classifying players. It saves the model in the registry and the artifacts for each experiment. The main objective of this pipeline is to make it easy for data scientists to set hyperparameters and save their models. This will help to prevent the spread of models across a repository into random Jupyter notebooks, without versioning. We know this is a common scenario that many data scientists are familiar with.</p>
<p align="middle"></p>
<p>It is worth mentioning that each node in this pipeline was planned using an experimental Jupyter Notebook. If you want to check the raw version, you can download it from <a href="https://github.com/robguilarr/Brawlstars-retention-pipeline/blob/main/notebooks/player_segmentation_node.ipynb" target="_blank" rel="noopener noreffer">here</a>.</p>
<p><strong>Node: <code>feature_scaler_node</code></strong></p>
<p>This node will use as input the player metadata, which includes descriptive data about the lifetime statistics for each player per battle-type score, to get more detail on the data specs you can refer to the <a href="https://brawlstats.readthedocs.io/en/latest/api.html#player" target="_blank" rel="noopener noreffer">&ldquo;Player&rdquo;</a> data model.</p>
<p>To train a <code>KMeans</code> model effectively, it&rsquo;s crucial to prepare the data by scaling it. Let&rsquo;s first review one of my recent <a href="https://github.com/robguilarr/Machine-Learning-Sandbox/blob/master/source/experiments/unsupervised_machine_learning/KMeans.ipynb" target="_blank" rel="noopener noreffer">experiments</a> before delving into the scaling methods. The scaling method we choose depends on the nature of the data and our analysis requirements. To choose the best scaling method for your project, here&rsquo;s a brief overview of each option:</p>
<ul>
<li><code>StandardScaler</code>: This scaling method scales each feature to have a mean of 0 and a standard deviation of 1. It&rsquo;s a good choice if our data follow a normal distribution and if we want to emphasize the differences between data points.</li>
<li><code>Normalizer</code>: This scaling method scales each sample to have a Euclidean length of 1. It&rsquo;s a good choice if we want to emphasize the direction of the data points and we&rsquo;re not interested in their magnitude.</li>
<li><code>MaxAbsScaler</code>: This scaling method scales each feature to have a maximum absolute value of 1. It&rsquo;s a good choice if we have sparse data or features with very different scales and we want to preserve the sparsity and relative magnitudes of the data, like when we have justified outliers.</li>
</ul>
<p>So, as we have sparse data and features with very different scales, and we want to preserve the sparsity and relative magnitudes of the data I used¬†<code>MaxAbsScaler</code>.</p>
<p><strong>Node: <code>feature_selector_node</code></strong></p>
<p>To ensure a correct classification process, it is important to select appropriate features to classify players, but it is equally important to determine the appropriate way to do so. In this case, I did not use a scientific approach to define it, but rather based it on game criteria.</p>
<p>I considered four attributes based on the next metrics:</p>
<ul>
<li>Trophies: The number of trophies earned by a player in Brawlstars is a significant indicator of their performance level and skill.</li>
<li>3 vs. 3 Victories: This attribute shows how many 3 vs. 3 matches the player has won, which could be an indication of their teamwork ability.</li>
<li>Solo and Duo Victories: These attributes represent the number of Solo or Duo matches the player has won, indicating their ability to play effectively without the support of teammates.</li>
<li>Best RoboRumbleTime: This attribute represents the player&rsquo;s best time in defeating robots in the Robo Rumble event, indicating their skill in handling PvE (player versus environment) situations.</li>
</ul>
<p><em>Note:</em> Since¬†<code>highestPowerPlayPoints</code>¬†refers to the highest score in a competitive mode that is no longer active, we will remove this feature. After all, according to¬†<a href="https://brawlstars.fandom.com/wiki/Power_Play#:~:text=Power%20Play%20Points&amp;text=The%20total%20number%20of%20Power,could%20be%20earned%20is%201386" target="_blank" rel="noopener noreffer">Brawlstars Wiki</a>,¬†this competitive mode could be unlocked after earning a Star Power for any Brawler, meaning that won&rsquo;t be a descriptive attribute for every player.</p>
<p>Also, these attributes can be divided into four descriptive <strong>inter-player interaction buckets</strong>: 3 vs. 3 Victories sessions, Duo and Solo sessions, and Experience. However, we will exclude PvE from this project since we should use different game design methods to ensure better analysis of the player&rsquo;s behavior versus the environment.</p>
<p>To determine the most appropriate method to use, we need to select the variables that can give us better performance given a model construction. We have three options to consider:</p>
<ul>
<li><code>VarianceThreshold</code>: This method removes all features whose variance doesn&rsquo;t meet a certain threshold. This technique is useful when our dataset has many features with low variance and can be removed without affecting the model&rsquo;s performance.</li>
<li><code>SelectKBest</code>: This technique selects the K most significant features based on statistical tests such as chi-squared or ANOVA.</li>
<li><code>Recursive Feature Elimination</code>: This method recursively removes features and evaluates the model&rsquo;s performance until the optimal number of features is reached. This method uses a model to assess the feature&rsquo;s importance and removes the least important ones iteratively.</li>
</ul>
<p>In conclusion, we also need to consider classifying players based on their preferred type of event and their historical score achieved, which is measured by <a href="https://brawlstars.fandom.com/wiki/Trophies" target="_blank" rel="noopener noreffer">trophies</a>. We can group highly skilled players with good teamwork into a cluster, while players with high solo and duo victories can be classified as excellent solo and duo players.</p>
<p>By defining these clusters, we can gain insights into the behavior and tendencies of different types of players and develop more targeted game design strategies. Therefore, we will set the parameter k of the <code>SelectKBest</code> method as 4 to select the top 4 features that can give the best model performance on the scaled data, which are going to be saved and versioned in the <code>/07_feature_store</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># ----- Parameters for feature selector ----</span><span class="w">
</span><span class="w"></span><span class="nt">feature_selector</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">top_features</span><span class="p">:</span><span class="w"> </span><span class="m">4</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p><strong>Node: <code>kmeans_estimator_grid_search_node</code></strong></p>
<p>We begin by obtaining the scaled data along with the selected features. Once the preparation is complete, we can proceed to train a model and create the estimator object. The resulting artifacts will be stored in our model registry, which can be found at the path <code>/08_model_registry</code> within our GCP bucket.</p>
<p>To determine the most suitable algorithm for our task, two key factors were considered: the dataset size and the desired number of clusters. For larger datasets, we favor the computationally efficient and faster <strong>K-Means</strong> algorithm. On the other hand, when working with smaller datasets, <strong>Hierarchical clustering</strong> emerges as a more appropriate choice.</p>
<p>K-Means is a highly effective <strong>partition-based</strong> clustering algorithm that groups data points into a predetermined number of clusters. It begins by randomly selecting initial centroids (cluster centers) and proceeds to iteratively assign each data point to the nearest centroid based on a chosen distance metric. After the assignment, the centroids are updated by calculating the mean distance of all the points within each cluster. This process repeats until the centroids no longer change, ensuring the clusters reach a stable state.</p>
<p>In summary, this particular node performs a grid search combined with cross-validation to identify the optimal hyperparameters for the KMeans clustering algorithm.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># ----- Parameters for player clustering ----</span><span class="w">
</span><span class="w"></span><span class="nt">kmeans_estimator_grid_search</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">random_state</span><span class="p">:</span><span class="w"> </span><span class="m">42</span><span class="w">
</span><span class="w">  </span><span class="nt">max_n_cluster</span><span class="p">:</span><span class="w"> </span><span class="m">13</span><span class="w">
</span><span class="w">  </span><span class="nt">starting_point_method</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;k-means++&#34;</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">max_iter</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="m">200</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">distortion_tol</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="m">0.0001</span><span class="p">]</span><span class="w">
</span><span class="w">  </span><span class="nt">cross_validations</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">  </span><span class="nt">cores</span><span class="p">:</span><span class="w"> </span>-<span class="m">1</span><span class="w">
</span><span class="w">  </span><span class="c"># Inertia plot dimensions in px</span><span class="w">
</span><span class="w">  </span><span class="nt">plot_dimensions</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">width</span><span class="p">:</span><span class="w"> </span><span class="m">500</span><span class="w">
</span><span class="w">    </span><span class="nt">height</span><span class="p">:</span><span class="w"> </span><span class="m">500</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>To enhance the evaluation process, we utilize the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" target="_blank" rel="noopener noreffer">GridSearch</a> method, allowing users to define and evaluate multiple parameters. Let&rsquo;s explore the key parameters:</p>
<ul>
<li><code>starting_point_method</code>: This parameter determines the method for selecting initial centroids in the K-means algorithm. We employ the <strong>k-means++</strong> initialization method, which enhances convergence by intelligently choosing initial centroids.</li>
<li><code>max_iter</code>: The maximum number of iterations that the K-means algorithm will perform is specified by this parameter. The algorithm will halt either when it reaches the specified <strong>max_iter</strong> iterations or when convergence is achieved before that.</li>
<li><code>distortion_tol</code>: This parameter controls the convergence criteria based on distortion (or inertia). The algorithm terminates if the change in distortion between two consecutive iterations falls below this value.</li>
<li><code>cores</code>: Used to define the number of cores used by the machine to evaluate and select the best model.</li>
</ul>
<p>By leveraging GridSearch, we can identify the model with the highest negative inertia. The selected model will be stored in the model registry as a pickle file. Additionally, a versioned inertia plot will be generated, enabling easy tracking of the number of clusters selected and evaluated.</p>
<p align="middle"></p>
<p>The node will capture four outputs, each one versioned with the execution timestamp from the pipeline:</p>
<ul>
<li><code>kmeans_estimator</code>: This output stores the trained model as a pickle file.</li>
<li><code>best_params_KMeans</code>: This output represents the optimal estimator chosen through the GridSearch method.</li>
<li><code>eval_params_KMeans</code>: This output contains the hyperparameters used for evaluating the GridSearch.</li>
<li><code>inertia_plot</code>: This output encompasses the inertia plot displayed earlier in the form of a Plotly JSON dataset.</li>
</ul>
<p><strong>Node: <code>kmeans_inference_node</code></strong></p>
<p>The next step is to evaluate the model. This node will import the model from the model registry, produce the inferences, and generate labels that will be saved in the <code>player_metadata_clustered</code> dataset. It will also produce four metrics to evaluate the model:</p>
<ul>
<li>Inertia: This metric measures the sum of distances between each point and its assigned cluster center. A lower inertia value indicates that the data points are closer to their respective centroids.</li>
<li>Silhouette score: This metric indicates how well each data point is assigned to its cluster. A higher silhouette score indicates that data points within a cluster are more similar to each other and dissimilar to points in other clusters.</li>
<li>Davies-Bouldin index: This metric evaluates the average similarity between each cluster and its most similar cluster, taking into account both the scatter within the cluster and the separation between different clusters. A lower Davies-Bouldin index indicates a better separation between clusters.</li>
<li>Calinski-Harabasz index: This metric measures the ratio of between-cluster variance to within-cluster variance. A higher Calinski-Harabasz index indicates a better separation between clusters.</li>
</ul>
<p>All of these metrics will be saved in the <code>metrics_KMeans</code> output, which will be saved as a model artifact and also versioned in our GCP model registry. This way, you will be able to visualize the experiment tracking in the <a href="https://docs.kedro.org/en/stable/visualisation/experiment_tracking.html" target="_blank" rel="noopener noreffer">Kedro Experiments</a> section, as shown below.</p>
<p align="middle"></p>
<p>This will allow you to track the performance of the model over time and identify any areas that need improvement.</p>
<p align="middle"></p>
<p><strong>Node: <code>centroid_plot_generator_node</code></strong></p>
<p>Finally, this node will generate visualizations of the centroids for each combination of X and Y variables. The plot below provides an example, where the centroids are represented by black-bordered squares.</p>
<p align="middle"></p>
<hr>
<h3 id="-player-activity-data-and-cluster-labels-merge-pipeline">üìä Player activity data and Cluster labels merge Pipeline</h3>
<p><strong>Pipeline <code>player_activity_clustering_merge</code></strong></p>
<p>The purpose of the upcoming pipeline is to streamline the process of augmenting the retention data generated by the <code>activity_transformer_node</code>. Specifically, this involves incorporating the tags and cluster labels obtained from the output produced by the <code>kmeans_inference_node</code>. The ultimate objective is to utilize this enriched dataset to generate compelling visualizations through the <code>user_retention_plot_gen_node</code>.</p>
<p align="middle"></p>
<p>To illustrate the capabilities of this pipeline, let&rsquo;s examine an example of the plots it can generate.</p>
<p align="middle"></p>
<p>The cohort window displays the bounded retention data for players belonging to &ldquo;Cluster 0&rdquo;. Among users who installed the game by January 1st, 2023, the analysis reveals that 87% returned after the first day, 78% returned after the third day, and 56% of them continued engagement after the seventh day. It is important to note that these results are intended solely for <strong>demonstrative</strong> purposes, as they may be subject to bias due to the data collection method employed.</p>
<h2 id="deployment-demo">üåê¬†Deployment Demo</h2>
<p>The deployment will be structured in a simple way to define an architecture that can run the job without complex services. In this case, I used a stateless service to run the job. The tech stack used is composed of the following elements:</p>
<ul>
<li><strong>GitHub repository:</strong>¬†The code repository containing the code assembled as a Kedro project framework. This repository has two branches: one for development (<code>feature/develop</code>) and another for deployments (<code>main</code>).</li>
<li><strong>Docker container:</strong>¬†A container created with a <a href="https://github.com/robguilarr/Brawlstars-retention-pipeline/blob/main/Dockerfile" target="_blank" rel="noopener noreffer">Dockerfile</a> that installs Java v8, Hadoop 3.1.1, and Spark 3.3.1 on top of a base image in Python 3.9. The container then executes the main¬†<code>CMD</code>¬†command to run the job.</li>
<li><strong>Google Cloud Bucket:</strong>¬†A place to store the raw data, staging data, and model artifacts. The bucket is structured to provide more traceability to the experiments.</li>
<li><strong>Google Cloud Build:</strong>¬†A service used for continuous development. When a user makes a pull request from the¬†<code>feature/develop</code>¬†branch to the¬†<code>main</code>¬†branch, an action is triggered in Google Cloud Build to rebuild the image based on the new code version.</li>
<li><strong>Google Cloud Run:</strong>¬†A computing platform with scalable infrastructure where the execution command is pointing, using the code image provided by the Cloud Build service.</li>
</ul>
<p align="middle"></p>
<p>Note that the execution of the code is pointing to the visualization command, that‚Äôs why the outputs are not loaded. This is because the main purpose of this deployment is to showcase this project. However, for a deployment on GCP, it is simple to change the <code>CMD</code> command at the end of the Dockerfile.</p>
<p>Additionally, the <a href="https://brawlstars-retention-pipeline-6u27jcczha-uw.a.run.app/" target="_blank" rel="noopener noreffer">deployment</a> was made public for this showcase using <a href="https://cloud.google.com/free/docs/free-cloud-features#cloud-run" target="_blank" rel="noopener noreffer">Google‚Äôs Free Program</a>, and a VPC was not set up to let you access the <a href="https://brawlstars-retention-pipeline-6u27jcczha-uw.a.run.app/" target="_blank" rel="noopener noreffer">pipeline view</a>.</p>
<h2 id="-final-thoughts--takeaways">üóíÔ∏è Final thoughts &amp; takeaways</h2>
<p><strong>What can the stakeholders understand and take into consideration?</strong></p>
<p>Implementing an automated and parametrized pipeline for bounded retention metrics allows for focused analysis of player engagement and behavior, providing actionable insights for game improvement.</p>
<p>Real-time and reliable data enables designers to identify trends, patterns, and potential issues affecting customer retention, facilitating the implementation of targeted strategies and interventions.</p>
<p><strong>What could the stakeholders do to take action?</strong></p>
<p>Planning the data processing method is crucial to assess scalability and long-term parallelization technologies, minimizing risks and optimizing resource allocation.</p>
<p>Establishing a robust monitoring system helps track key metrics and performance indicators before and after new season releases, aiding in the identification of potential data drift sources.</p>
<p>Implementing good practices in Continuous Development allows for seamless productionalization of new changes and facilitates testing and deployment.</p>
<p>To compare different modeling strategies, A/B testing can be used by assembling new nodes to alternative versions of the same pipeline.</p>
<p><strong>What can stakeholders keep working on?</strong></p>
<p>Centralizing the solution into a single cloud provider, like Google Cloud Services, minimizes tech debt, simplifies management, and optimizes resource allocation and cost management.</p>
<p>Leveraging tools like <a href="https://docs.kedro.org/en/stable/visualisation/experiment_tracking.html#when-should-i-use-experiment-tracking-in-kedro" target="_blank" rel="noopener noreffer">Kedro</a>, MLflow, and Neptune.ai for experiment tracking helps keep artifacts versioned and trackable over time, enhancing reproducibility and collaboration</p>
<hr>
<h2 id="‚Ñπ-additional-information">‚ÑπÔ∏è Additional Information</h2>
<ul>
<li><strong>About the article</strong></li>
</ul>
<p>The following article is provided strictly for learning purposes and is intended solely as a learning tool for the author. The content of this article represents the author&rsquo;s personal perspectives and does not rely on established or experienced methods commonly employed in the field. The practices and methodologies discussed herein are not reflective of the opinions or views held by the author&rsquo;s employer. It is strongly advised against utilizing this article directly as a solution, as the process of data collection and utilization of public APIs may introduce biases and inaccuracies. Users are cautioned to exercise caution and discretion when considering its use.</p>
<ul>
<li><strong>Related Content</strong></li>
</ul>
<p>Here you can find a list of preferred materials if you are interested in similar topics</p>
<p>‚Äî <a href="https://podcasts.apple.com/us/podcast/elite-game-developers-podcast/id1463752909" target="_blank" rel="noopener noreffer">Elite Game Developers Podcast</a> by Joakim Achren.</p>
<p>‚Äî Joakim Achren newsletter and <a href="https://www.elitegamedevelopers.com/blog/?ref=elitegamedevelopers.com" target="_blank" rel="noopener noreffer">blog</a>.</p>
<p>‚Äî Game Data Science book and additional info at the¬†<a href="https://global.oup.com/academic/product/game-data-science-9780192897879?cc=cr&amp;lang=en&amp;" target="_blank" rel="noopener noreffer">Oxford University Press</a>.</p>
<p>‚Äî Getting started with <a href="https://docs.kedro.org/en/stable/get_started/install.html" target="_blank" rel="noopener noreffer">Kedro</a>.</p>
<p>‚Äî Brawstats <a href="https://brawlstats.com/" target="_blank" rel="noopener noreffer">homepage</a>, by overwolf.</p>
<ul>
<li><strong>Datasets</strong></li>
</ul>
<p>The output dataset will be uploaded to Kaggle as part of its public source intention.</p>
]]></description>
</item>
</channel>
</rss>
